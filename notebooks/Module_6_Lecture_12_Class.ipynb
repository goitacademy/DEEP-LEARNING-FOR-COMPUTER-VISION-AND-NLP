{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed5c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python3 -m spacy download en\n",
    "# ! python3 -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "193eed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import de_core_news_sm\n",
    "\n",
    "import datasets\n",
    "import torchtext\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f9cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7492897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"bentrevett/multi30k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ddc9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 29000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1014\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7331aed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, valid_data, test_data = dataset[\"train\"], dataset[\"validation\"], dataset[\"test\"]\n",
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0edf1be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>de</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two young, White males are outside near many bushes.</td>\n",
       "      <td>Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Several men in hard hats are operating a giant pulley system.</td>\n",
       "      <td>Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A little girl climbing into a wooden playhouse.</td>\n",
       "      <td>Ein kleines Mädchen klettert in ein Spielhaus aus Holz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man in a blue shirt is standing on a ladder cleaning a window.</td>\n",
       "      <td>Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two men are at the stove preparing food.</td>\n",
       "      <td>Zwei Männer stehen am Herd und bereiten Essen zu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 en  \\\n",
       "0              Two young, White males are outside near many bushes.   \n",
       "1     Several men in hard hats are operating a giant pulley system.   \n",
       "2                   A little girl climbing into a wooden playhouse.   \n",
       "3  A man in a blue shirt is standing on a ladder cleaning a window.   \n",
       "4                          Two men are at the stove preparing food.   \n",
       "\n",
       "                                                                            de  \n",
       "0            Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.  \n",
       "1              Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.  \n",
       "2                      Ein kleines Mädchen klettert in ein Spielhaus aus Holz.  \n",
       "3  Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.  \n",
       "4                            Zwei Männer stehen am Herd und bereiten Essen zu.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    example_df = pd.DataFrame(train_data[:5])\n",
    "    display(example_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9273b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = en_core_web_sm.load()\n",
    "de_nlp = de_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c765982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(    \n",
    "    example,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    max_length,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token\n",
    "):\n",
    "    '''\n",
    "    Tokenizes a textual English-German input pair.    \n",
    "    Args:\n",
    "        example: (dict) a dictionary with one phrase in English and German; keys 'en', 'de'\n",
    "        en_nlp: (spacy.lang) a spacy language model for English\n",
    "        de_nlp: (spacy.lang) a spacy language model for German\n",
    "        max_length: (int) max input sentence length, symbols\n",
    "        lower: (bool) if to lowercase input\n",
    "        sos_token: (str) a start_of_sequence token\n",
    "        eos_token: (str) an end_of_sequence token\n",
    "    \n",
    "    Return:    \n",
    "        (dict) pre-processed and tokenized input sequence  \n",
    "    '''\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d7e4ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113dbf1bf92645b7b173346f19fda309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pre-process input data\n",
    "\n",
    "max_length = 1_000\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp, \n",
    "    \"de_nlp\": de_nlp, \n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77337e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiße',\n",
       "  'männer',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nähe',\n",
       "  'vieler',\n",
       "  'büsche',\n",
       "  '.',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac547f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a vocab\n",
    "\n",
    "min_freq = 2 # minimum frequency of occurrence in the text\n",
    "unk_token = \"<unk>\" # unknown token\n",
    "pad_token = \"<pad>\" # padding token\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "de_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"de_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "508de79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "assert en_vocab[unk_token] == de_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == de_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]\n",
    "\n",
    "print(unk_index)\n",
    "print(pad_index)\n",
    "\n",
    "print(en_vocab['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "143cbb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting default value for oov words\n",
    "\n",
    "en_vocab.set_default_index(unk_index)\n",
    "de_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67902b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_vocab, de_vocab):\n",
    "    '''\n",
    "    Creates a mapping from string tokens to the vocabulary indexes.\n",
    "    '''\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    de_ids = de_vocab.lookup_indices(example[\"de_tokens\"])\n",
    "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b58540de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19c65f2847b4e538ed99584b1d20712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fn_kwargs = {\n",
    "    \"en_vocab\": en_vocab, \n",
    "    \"de_vocab\": de_vocab\n",
    "}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7021fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiße',\n",
       "  'männer',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nähe',\n",
       "  'vieler',\n",
       "  'büsche',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'en_ids': [2, 16, 24, 15, 25, 778, 17, 57, 80, 202, 1312, 5, 3],\n",
       " 'de_ids': [2, 18, 26, 253, 30, 84, 20, 88, 7, 15, 110, 7647, 3171, 4, 3]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1fa9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to torch Dataset format\n",
    "\n",
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"de_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type, \n",
    "    columns=format_columns, \n",
    "    output_all_columns=True\n",
    ")\n",
    "\n",
    "valid_data = valid_data.with_format(\n",
    "    type=data_type, \n",
    "    columns=format_columns, \n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type, \n",
    "    columns=format_columns, \n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deeddf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['en', 'de', 'en_tokens', 'de_tokens', 'en_ids', 'de_ids'],\n",
       "    num_rows: 29000\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3be7dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([   2,   16,   24,   15,   25,  778,   17,   57,   80,  202, 1312,    5,\n",
       "            3]),\n",
       " 'de_ids': tensor([   2,   18,   26,  253,   30,   84,   20,   88,    7,   15,  110, 7647,\n",
       "         3171,    4,    3]),\n",
       " 'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiße',\n",
       "  'männer',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nähe',\n",
       "  'vieler',\n",
       "  'büsche',\n",
       "  '.',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "81a9f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    '''\n",
    "    Adding padding as a part of a collate_fn.\n",
    "    '''\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_de_ids = [example[\"de_ids\"] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"de_ids\": batch_de_ids,\n",
    "        }\n",
    "        return batch\n",
    "    \n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c6e4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    \n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    \n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57383489",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0b25352e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc82f758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
       "         [  4,   4,   4,  ..., 209,  16,   4],\n",
       "         [ 55,   9,  64,  ...,  10, 492,   9],\n",
       "         ...,\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1]]),\n",
       " 'de_ids': tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
       "         [  5,   5,   8,  ...,  39,  18,   5],\n",
       "         [ 49,  13,  67,  ...,  48, 352,  13],\n",
       "         ...,\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1]])}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5b228450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, encoder_hidden_dim, bidirectional = True)\n",
    "        self.fc = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "        \n",
    "    def forward(self, src): # (src_length, batch size)\n",
    "        embedded = self.embedding(src) # (src_length, batch_size, embedding_dim)\n",
    "\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs (src_length, batch_size, hidden dim * n_directions)\n",
    "        # hidden (n_layers * n_directions, batch_size, hidden dim)\n",
    "        \n",
    "        # hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        \n",
    "        # outputs are always from the last layer\n",
    "        # hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        # hidden [-1, :, : ] is the last of the backwards RNN\n",
    "       \n",
    "        # initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        # encoder RNNs fed through a linear layer\n",
    "        \n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
    "        \n",
    "        # outputs (src_length, batch_size, encoder_hidden_dim * 2)\n",
    "        # hidden (batch_size, decoder_hidden_dim)\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "38e906d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn_fc = nn.Linear(\n",
    "            (encoder_hidden_dim * 2) + decoder_hidden_dim, \n",
    "            decoder_hidden_dim\n",
    "        )\n",
    "        self.v_fc = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):        \n",
    "        # hidden (batch_size, decoder_hidden_dim)\n",
    "        # encoder_outputs (src_length, batch_size, encoder_hidden dim * 2)\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_length = encoder_outputs.shape[0]\n",
    "        \n",
    "        # repeat decoder hidden state src_length times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_length, 1) # (batch_size, src_length, decoder_hidden_dim)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2) # (batch_size, src_length, encoder_hidden_dim * 2)\n",
    "        \n",
    "        energy = torch.tanh(self.attn_fc(torch.cat((hidden, encoder_outputs), dim=2))) \n",
    "        # (batch_size, src_length, decoder_hidden_dim)\n",
    "\n",
    "        attention = self.v_fc(energy).squeeze(2) # batch_size, src_length\n",
    "\n",
    "        return torch.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c5b1313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim,\n",
    "        embedding_dim,\n",
    "        encoder_hidden_dim,\n",
    "        decoder_hidden_dim,\n",
    "        attention,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU((encoder_hidden_dim * 2) + embedding_dim, decoder_hidden_dim) \n",
    "        self.fc_out = nn.Linear(\n",
    "            (encoder_hidden_dim * 2) + decoder_hidden_dim + embedding_dim, \n",
    "            output_dim\n",
    "        )\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input = (batch_size)\n",
    "        # hidden = batch_size, decoder hidden dim]\n",
    "        # encoder_outputs = [src length, batch size, encoder hidden dim * 2]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.embedding(input)\n",
    "        #embedded = [1, batch size, embedding dim]\n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        # a = [batch size, src length]\n",
    "        a = a.unsqueeze(1)\n",
    "        # a = [batch size, 1, src length]\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # encoder_outputs = [batch size, src length, encoder hidden dim * 2]\n",
    "        weighted = torch.bmm(a, encoder_outputs) # batch matrix-matrix product\n",
    "        # weighted = [batch size, 1, encoder hidden dim * 2]\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        # weighted = [1, batch size, encoder hidden dim * 2]\n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        # rnn_input = [1, batch size, (encoder hidden dim * 2) + embedding dim]\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        # output = [seq length, batch size, decoder hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, decoder hid dim]\n",
    "        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, decoder hidden dim]\n",
    "        # hidden = [1, batch size, decoder hidden dim]\n",
    "        # this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "        #prediction = [batch size, output dim]\n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b07a13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        batch_size = src.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        # hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        # outputs = [src length, batch size, encoder hidden dim * 2]\n",
    "        # hidden = [batch size, decoder hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            # receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [n layers, batch size, decoder hidden dim]\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "34b9871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(de_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "encoder_hidden_dim = 512\n",
    "decoder_hidden_dim = 512\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_dir = './saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0075653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn_fc): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v_fc): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = Attention(encoder_hidden_dim, decoder_hidden_dim)\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    encoder_hidden_dim,\n",
    "    decoder_hidden_dim\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    encoder_hidden_dim,\n",
    "    decoder_hidden_dim,\n",
    "    attention,\n",
    ")\n",
    "\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e4fde990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn_fc): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v_fc): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "    Initiates model weights from the normal distribution.\n",
    "    Sets bias to 0.\n",
    "    \"\"\"\n",
    "    for name, param in m.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5ec34207",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f8121295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in tqdm(enumerate(data_loader)):\n",
    "        src = batch[\"de_ids\"].to(device)\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"de_ids\"].to(device)\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9c24aee4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9de32bc1854cad8fa227e528e581b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b4422b003c45e1a4bf70fb211e68fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m best_valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_epochs)):\n\u001b[0;32m----> 9\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate_fn(\n\u001b[1;32m     20\u001b[0m         model, \n\u001b[1;32m     21\u001b[0m         valid_data_loader, \n\u001b[1;32m     22\u001b[0m         criterion, \n\u001b[1;32m     23\u001b[0m         device,\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_loss \u001b[38;5;241m<\u001b[39m best_valid_loss:\n",
      "Cell \u001b[0;32mIn[110], line 18\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# trg = [(trg length - 1) * batch size]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, trg)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0 # gradient clipping\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "        \n",
    "    train_loss = train_fn(\n",
    "        model, \n",
    "        train_data_loader, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        clip, \n",
    "        teacher_forcing_ratio, \n",
    "        device,\n",
    "    )\n",
    "    \n",
    "    valid_loss = evaluate_fn(\n",
    "        model, \n",
    "        valid_data_loader, \n",
    "        criterion, \n",
    "        device,\n",
    "    )\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, 'en_fr.pt'))\n",
    "    \n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aad11458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.276\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(model_dir, 'en_fr.pt'), map_location=device))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8b8a5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(\n",
    "    sentence, \n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(sentence, str):\n",
    "            de_tokens = [token.text for token in de_nlp.tokenizer(sentence)]\n",
    "        else:\n",
    "            de_tokens = [token for token in sentence]\n",
    "        if lower:\n",
    "            de_tokens = [token.lower() for token in de_tokens]\n",
    "        de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "        ids = de_vocab.lookup_indices(de_tokens)\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        encoder_outputs, hidden = model.encoder(tensor)\n",
    "        inputs = en_vocab.lookup_indices([sos_token])\n",
    "        attentions = torch.zeros(max_output_length, 1, len(ids))\n",
    "        for i in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden, attention = model.decoder(inputs_tensor, hidden, encoder_outputs)\n",
    "            attentions[i] = attention\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "        en_tokens = en_vocab.lookup_tokens(inputs)\n",
    "    return en_tokens, de_tokens, attentions[:len(en_tokens)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8d7e5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(sentence, translation, attention):\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    attention = attention.squeeze(1).numpy()\n",
    "    cax = ax.matshow(attention, cmap=\"bone\")\n",
    "    ax.set_xticks(ticks=np.arange(len(sentence)), labels=sentence, rotation=90, size=15)\n",
    "    translation = translation[1:]\n",
    "    ax.set_yticks(ticks=np.arange(len(translation)), labels=translation, size=15)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "44b7c556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.',\n",
       " 'A man in an orange hat starring at something.')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = test_data[0][\"de\"]\n",
    "expected_translation = test_data[0][\"en\"]\n",
    "\n",
    "sentence, expected_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bc7216ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', 'a', 'man', 'in', 'an', 'orange', 'hat', 'welding', 'something', '.', '<eos>']\n",
      "['<sos>', 'ein', 'mann', 'mit', 'einem', 'orangefarbenen', 'hut', ',', 'der', 'etwas', 'anstarrt', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "translation, sentence_tokens, attention = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")\n",
    "\n",
    "print(translation)\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "25099a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention(sentence_tokens, translation, attention)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
